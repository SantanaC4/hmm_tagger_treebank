{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hmm_tagger.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMCMHx8Fj5ir1yimDQFAui/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SantanaC4/hmm_tagger_treebank/blob/main/hmm_tagger.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation part of speech tagging from treebank corpus using Hidden Markov Model approach"
      ],
      "metadata": {
        "id": "OkuTPbMUQlDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import pprint, time"
      ],
      "metadata": {
        "id": "yu28aeFqQkwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload Penn Treebank Corpus"
      ],
      "metadata": {
        "id": "2Wzh1i1AQTDh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "im0rFG2LDdFk"
      },
      "outputs": [],
      "source": [
        "# That function filter the pair (word, tag) and remove nonsense (like: ''_'') pair of the dataset\n",
        "\n",
        "def pair_filter(section):\n",
        "  if (section == \"training\"):\n",
        "    url = 'https://raw.githubusercontent.com/SantanaC4/hmm_tagger_treebank/main/treebank_dataset/Sec0-18_training'\n",
        "  if (section == \"development\"):\n",
        "    url = 'https://raw.githubusercontent.com/SantanaC4/hmm_tagger_treebank/main/treebank_dataset/Sec-19-21_development'\n",
        "  if (section == \"testing\"):\n",
        "    url = 'https://raw.githubusercontent.com/SantanaC4/hmm_tagger_treebank/main/treebank_dataset/Sec-22-24_testing'\n",
        "\n",
        "  df = pd.read_csv(url, header=None, sep='\\n')\n",
        "  spliting =  [i.split(\" \") for i in df[0]]\n",
        "  pair_wordTag = []\n",
        "  tags = []\n",
        "  words = []\n",
        "\n",
        "  count = 0\n",
        "  for i in spliting:\n",
        "    if (len(i) == 1):\n",
        "      if (i[0] != \"''_''\"):\n",
        "          word, tag = i[0].split(\"_\")\n",
        "          pair_wordTag.append(tuple([word, tag]))\n",
        "          tags.append(tag)\n",
        "          words.append(word)\n",
        "    else:\n",
        "      for j in i:\n",
        "        if (j != \"''_''\" and j != \"'_''\"):\n",
        "          word, tag = j.split(\"_\")\n",
        "          pair_wordTag.append(tuple([word, tag]))\n",
        "          tags.append(tag)\n",
        "          words.append(word)\n",
        "  return (pair_wordTag, tags, words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pair_wordTag,tags,words= pair_filter(\"training\")\n",
        "print(words[0:10])\n",
        "print(tags[0:10])\n",
        "print(pair_wordTag[0:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-UipHAMQ87E",
        "outputId": "1d3d5456-52ff-4d27-8c11-6cfe3eca9e88"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the']\n",
            "['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT']\n",
            "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HMM class"
      ],
      "metadata": {
        "id": "nuG-HzKyTphV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HMM:\n",
        "  def __init__(self, text, n):\n",
        "        self.bigram_cnt = defaultdict(int)\n",
        "        self.unigram_cnt = defaultdict(int)\n",
        "        self.tag_word_count = defaultdict(int)\n",
        "        self.transition_probabilities = defaultdict(int)\n",
        "        self.emmission_probabilities = defaultdict(int)\n",
        "        self.ngrams(text, n)\n",
        "\n",
        "  def ngrams(self, text, n):\n",
        "        n_grams = []\n",
        "        text = [\"START\"] + text\n",
        "        for i in range(len(text)): \n",
        "            n_grams.append(tuple(text[i: i + n]))\n",
        "\n",
        "        n_grams[-1] = tuple([n_grams[-1][0], \"END\"]) \n",
        "        if (n == 2):\n",
        "          for bigram in n_grams:\n",
        "              self.bigram_cnt[bigram] += 1\n",
        "              self.unigram_cnt[bigram[0]] += 1\n",
        "              self.unigram_cnt[bigram[1]] += 1\n",
        "        return n_grams\n",
        "\n",
        "  def transition_probability(self, tags):\n",
        "        bigrams = self.ngrams(tags, 2)\n",
        "        for bigram in bigrams:\n",
        "            self.transition_probabilities[bigram] = self.bigram_cnt[bigram] / self.unigram_cnt[bigram[0]]\n",
        "        return self.transition_probabilities\n",
        "\n",
        "  def emmission_probability(self, tagged_words):\n",
        "        for word, tag in tagged_words:\n",
        "            self.tag_word_count[tuple([word, tag])] += 1\n",
        "        for word, tag in tagged_words:\n",
        "            self.emmission_probabilities[tuple([word, tag])] = self.tag_word_count[tuple([word, tag])] / self.unigram_cnt[tag]\n",
        "        return self.emmission_probabilities\n",
        "  \n",
        "  def Viterbi(self, words, tags):\n",
        "    state = []\n",
        "    \n",
        "    for k, word in enumerate(words):\n",
        "      #initialise list of probability column for a given observation\n",
        "      p = []\n",
        "      for tag in tags:\n",
        "        if k == 0:\n",
        "          transition_p = self.transition_probabilities[('.', tag)]\n",
        "        else:\n",
        "          transition_p = self.transition_probabilities[state[-1], tag]\n",
        "        \n",
        "        # compute emissino and state probabilities\n",
        "        emission_p = self.emmission_probabilities[(words[k],tag)]\n",
        "        state_probability = emission_p * transition_p    \n",
        "        p.append(state_probability)\n",
        "             \n",
        "      pmax = max(p)\n",
        "      # getting state for which probability is maximum\n",
        "      state_max = tags[p.index(pmax)]\n",
        "      state.append(state_max)\n",
        "    return list(zip(words, state))\n",
        "  "
      ],
      "metadata": {
        "id": "2TBGcq2OUG5g"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags_space = pair_filter(\"training\")[1]\n",
        "tagge_words = pair_filter(\"training\")[0]\n",
        "\n",
        "a = HMM(tags_space, 2)\n",
        "a.transition_probability(tags_space)\n",
        "a.emmission_probability(tagge_words)\n",
        "\n",
        "\n",
        "test = \"Will can see Marry\".split()\n",
        "a.Viterbi(test, tags_space)"
      ],
      "metadata": {
        "id": "gV5mlbvXkpHQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2d933fd-28cc-4834-f3ae-fae6eebdf2e5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Will', 'NNP'), ('can', 'MD'), ('see', 'VB'), ('Marry', 'NNP')]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Code to test all the test sentences\n",
        "# tagging the test sentences()\n",
        "tags_space = pair_filter(\"testing\")[1]\n",
        "tagge_words = pair_filter(\"testing\")[0]\n",
        "test_untagged_words = pair_filter(\"testing\")[2]\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "a = HMM(tags_space, 2)\n",
        "a.transition_probability(tags_space)\n",
        "a.emmission_probability(tagge_words)\n",
        "tagged_seq = a.Viterbi(test_untagged_words, tags_space)\n",
        "end = time.time()\n",
        "difference = end-start\n",
        " \n",
        "print(\"Time taken in seconds: \", difference)\n",
        " \n",
        "# accuracy\n",
        "check = [i for i, j in zip(tagged_words, test_untagged_words) if i == j] \n",
        " \n",
        "accuracy = len(check)/len(tagged_seq)\n",
        "print('Viterbi Algorithm Accuracy: ',accuracy*100)"
      ],
      "metadata": {
        "id": "M8w5gYrYjEw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Lut8xmlagqMu"
      }
    }
  ]
}